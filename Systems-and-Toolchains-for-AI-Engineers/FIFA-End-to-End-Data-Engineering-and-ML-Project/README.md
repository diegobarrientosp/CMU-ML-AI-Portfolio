#  **FIFA End-to-End Data Engineering & Machine Learning Project**

---

## ğŸš€ **1. Introduction**

This project implements a **complete end-to-end data engineering and machine learning pipeline** using the FIFA-22 player dataset. It covers every major stage of a modern ML system, including:

* Data ingestion & transformation
* SQL database design and population
* Scalable feature engineering with PySpark
* Classical ML modeling (Linear Regression & Random Forest)
* Deep Learning with PyTorch (GPU-accelerated)
* Cloud-ready architecture and Kafka streaming integration

The objective is to demonstrate strong engineering practices for **reliable**, **scalable**, and **reproducible** machine learning systems.

---

## âš™ï¸ **2. Tools & Technologies Used**

### **ğŸ§± Data Engineering**

* **PostgreSQL** â€” relational storage for structured FIFA data
* **SQL (DDL + queries)** â€” table creation, constraints, and ingestion
* **PySpark** â€” distributed processing & scalable feature engineering

### **ğŸ§  Machine Learning**

* **PySpark MLlib** â€” baseline models (Linear Regression, Random Forest)
* **PyTorch** â€” GPU-accelerated neural networks with customized architectures

### **ğŸ“Š Additional Libraries**

* Pandas
* Matplotlib
* Seaborn
* confluent_kafka
* google-api-python-client

Tools were selected to simulate a **real-world ML pipeline**, mixing big-data frameworks (Spark), SQL databases, and deep learning tooling.

---

## ğŸ“‚ **3. Repository Structure**

```
FIFA-End-to-End-Data-Engineering-and-ML-Project/
â”‚
â”œâ”€â”€ notebooks/              # Main notebooks (local + cloud versions)
â”‚   â”œâ”€â”€ Project_Final.ipynb
â”‚   â””â”€â”€ Project_Final_Cloud.ipynb
â”‚
â”œâ”€â”€ sql/                    # PostgreSQL schema + ingestion query
â”‚   â””â”€â”€ Create_fifa_table.sql
â”‚
â”œâ”€â”€ models/                 # Saved trained PyTorch model
â”‚   â””â”€â”€ best_model_shallow_4.pt
â”‚
â”œâ”€â”€ data/                   # Data link only (no CSVs stored)
â”‚   â””â”€â”€ README.md           # Dataset download link from Kaggle
â”‚
â”œâ”€â”€ README.md               # Project documentation
â””â”€â”€ .gitignore
```

---

## ğŸ“¥ **4. Dataset**

The dataset used in this project is publicly available on Kaggle:

ğŸ”— **[https://www.kaggle.com/stefanoleone992/fifa-22-complete-player-dataset](https://www.kaggle.com/stefanoleone992/fifa-22-complete-player-dataset)**

**Note:**
CSV files are **not included** in the repository due to size limits.
Users should download the files from Kaggle and place them in the appropriate local directory.

---

## ğŸ› ï¸ **5. How to Run the Project**

### **Local Execution**

1. Install dependencies from the notebook or your own environment
2. Load the dataset downloaded from Kaggle
3. Execute `Project_Final.ipynb`

### **Cloud Execution**

If running on Dataproc / Google Cloud:
Execute `Project_Final_Cloud.ipynb`, which is adapted for cloud-based Spark runtime.

---

## ğŸ§ª **6. Machine Learning Models Implemented**

### **PySpark Baselines**

| Model             | RMSE  | MAE   | RÂ²    | Notes                  |
| ----------------- | ----- | ----- | ----- | ---------------------- |
| Linear Regression | ~1.86 | ~1.43 | ~0.93 | Strong simple baseline |
| Random Forest     | ~1.15 | ~0.82 | ~0.97 | **Best overall model** |

### **PyTorch Neural Networks**

Four architectures were developed and tested:

* **NN-1:** Simple baseline
* **NN-2:** Increased regularization
* **NN-3:** Deeper model with dropout
* **NN-4:** *Best NN model* (balanced depth & regularization)

Final NN performance (best):

* RMSE â‰ˆ 2.94
* MAE â‰ˆ 2.32
* RÂ² â‰ˆ 0.82

**Conclusion:**
Random Forest generalizes best for this problem, outperforming neural networks.

---

## ğŸ—ï¸ **7. Project Workflow Overview**

1. **Load raw FIFA CSVs**
2. **Create PostgreSQL table** using `Create_fifa_table.sql`
3. **Ingest data** into database
4. **Load into PySpark** for scalable feature engineering
5. **Train ML models**
6. **Evaluate performance** across models
7. **Train Deep Learning models** in PyTorch (GPU)
8. **Save best model** to `/models/`
9. *(Optional)* **Kafka streaming** to process YouTube comments in real-time
